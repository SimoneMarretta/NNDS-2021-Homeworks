{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdnnRxTNdyW1"
   },
   "source": [
    "# Neural Networks for Data Science Applications\n",
    "## Mid-term Homework: Implementing a custom activation function\n",
    "\n",
    "**Name**: Simone Marretta\n",
    "\n",
    "**Matricola**: 1911358\n",
    "\n",
    "Send the completed notebook before 26/11/2020 back to **simone.scardapane@uniroma1.it** with the object \"[NNDS] Homework_1_\\<id\\>\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "PEr8qV6-nMuL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAEgygyPfO7b"
   },
   "source": [
    "### Introduction\n",
    "\n",
    "The **exponential linear unit** (ELU) is an activation function defined as [1]:\n",
    "\n",
    "$$\n",
    "\\phi(x) =\n",
    "\\Biggl\\{ \n",
    "\\begin{align} \n",
    "x & \\;\\; \\text{ if } x \\ge 0 \\\\\n",
    "\\alpha \\left(\\exp\\left(x\\right)- 1\\right) & \\;\\; \\text{ otherwise } \n",
    "\\end{align}\n",
    "\\Bigr.\n",
    "\\,,\n",
    "$$\n",
    "\n",
    "where $\\alpha$ is a hyper-parameter. The function is implemented in `tf.keras.layers.ELU` (see the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ELU)).\n",
    "\n",
    "The **parametric ELU** (PELU) extends the ELU activation function as [2]:\n",
    "\n",
    "$$\n",
    "\\phi(x) =\n",
    "\\Biggl\\{ \n",
    "\\begin{align} \n",
    "\\frac{\\alpha}{\\beta}x & \\;\\; \\text{ if } x \\ge 0 \\\\\n",
    "\\alpha \\left(\\exp\\Bigl(\\frac{x}{\\beta}\\Bigr)- 1\\right) & \\;\\; \\text{ otherwise } \n",
    "\\end{align}\n",
    "\\Bigr.\n",
    "\\,,\n",
    "$$\n",
    "\n",
    "where the major difference is that $\\alpha,\\beta > 0$ are *trainable* parameters, i.e., a pair of $(\\alpha, \\beta)$ values is trained for each unit in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5u4aF6Z4maHd"
   },
   "source": [
    "### Exercise 1: implement the PELU\n",
    "\n",
    "In TensorFlow, it is possible to implement new layers by subclassing `tf.keras.layers.Layer`:\n",
    "\n",
    "+ [Making new Layers and Models via subclassing](https://www.tensorflow.org/guide/keras/custom_layers_and_models)\n",
    "+ [Custom layers](https://www.tensorflow.org/tutorials/customization/custom_layers)\n",
    "+ [tf.keras.layers.Layer (documentation)](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer)\n",
    "\n",
    "**Exercise 1**: *After carefully reading the guides*, complete the following implementation of the PELU activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DfCpFg2xdug_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import NonNeg\n",
    "\n",
    "class PELU(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=32):\n",
    "        super(PELU, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #initializer = tf.random_uniform_initializer(minval = 0.1)\n",
    "        initializer = tf.constant_initializer(value=0.1)\n",
    "        self.a = self.add_weight(name='alpha',initializer=initializer,shape=[self.units],trainable=True,constraint=NonNeg())\n",
    "        self.b = self.add_weight(name='beta',initializer=initializer,shape=[self.units],trainable=True,constraint=NonNeg())\n",
    "\n",
    "    def call(self, inputs):\n",
    "      return (self.a/self.b)*tf.maximum(0., inputs) + self.a * (tf.exp(tf.minimum(0., inputs)/self.b)-1)\n",
    "\n",
    "    def get_config(self):\n",
    "      base_config = super().get_config()\n",
    "      return {**base_config, \"units\": self.units}\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8MEZxqbn8vs"
   },
   "source": [
    "**Hints for a correct implementation**:\n",
    "\n",
    "1. The layer (probably) requires two sets of trainable variables, whose shape depends on the number of units.\n",
    "2. From the definition of the PELU, $\\alpha, \\beta$ are required to be positive in order to ensure differentiability. The simplest way to handle this is to use a [constraint callable](https://www.tensorflow.org/api_docs/python/tf/keras/constraints) when creating the weight (see also the [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer) for `add_weight`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QY0TfCxo9yd"
   },
   "source": [
    "### Exercise 2: some preliminary tests\n",
    "\n",
    "To evaluate your implementation, let us start by creating a single PELU function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "DFNFXarBe8DV"
   },
   "outputs": [],
   "source": [
    "pelu = PELU(units=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWY76mEepSgj"
   },
   "source": [
    "**Exercise 2.1**: plot the function using the skeleton code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "id": "jdK0CyscfDtC",
    "outputId": "fe196673-ef42-4293-c3e6-72c4c7fefdc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer pelu_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc6fa0bb198>]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_range = tf.linspace(-5, 5, 200) # An equispaced grid of 200 points in [-5, +5]\n",
    "\n",
    "\n",
    "y_range = pelu(x_range)\n",
    "\n",
    "plt.plot(x_range.numpy(), y_range.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyGIlR_aqayc"
   },
   "source": [
    "The derivative of a PELU function with respect to the $\\alpha$ parameter is given by [2]:\n",
    "\n",
    "$$\n",
    "\\frac{d\\phi(x)}{d\\alpha} =\n",
    "\\Biggl\\{ \n",
    "\\begin{align} \n",
    "\\frac{x}{\\beta} & \\;\\; \\text{ if } x \\ge 0 \\\\\n",
    " \\left(\\exp\\Bigl(\\frac{x}{\\beta}\\Bigr)- 1\\right) & \\;\\; \\text{ otherwise } \n",
    "\\end{align}\n",
    "\\Bigr.\n",
    "\\,,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnvkoRVAqwg1"
   },
   "source": [
    "**Exercise 2.2**: using a `tf.GradientTape` object, compute the derivative above using automatic differentiation, and check its correctness up to a certain numerical precision.\n",
    "\n",
    "**Hints for a correct implementation**:\n",
    "\n",
    "1. `tf.GradientTape` allows to compute the derivative *at a single point x*. If you prefer to avoid a loop over all possible points, consider using the `jacobian` function to obtain them in a single pass ([Advanced Automatic Differentiation](https://www.tensorflow.org/guide/advanced_autodiff)).\n",
    "2. Given two tensors x and y, a simple way to compute elementwise similarity up to a certain precision (e.g., $10^{-4}$), is given by `tf.reduce_all(tf.abs(x - y) < 1e-4)`.\n",
    "\n",
    "**Exercise 2.3 (optional)**: try the same for the $\\beta$ parameter (you can check the analytical formula for the gradient in the original paper [2]). **Careful**: the equation in the original paper has a missing $h$ (thanks to Davide Aureli and Federico Siciliano for spotting this). See [the correct derivation](https://www.wolframalpha.com/input/?i=d%28a*%28exp%28h%2Fb%29-1%29%29%2Fdb) on Wolfram Alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OHxVU3fskYU7"
   },
   "outputs": [],
   "source": [
    "#Gradients with autograd\n",
    "x = tf.cast(tf.linspace(-5, 5, 200), tf.float32)\n",
    "with tf.GradientTape() as t:\n",
    "  t.watch(x)\n",
    "  y = pelu(x)\n",
    "auto_grads = t.jacobian(y,pelu.trainable_variables[0])\n",
    "auto_grads = tf.reshape(auto_grads, [-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVmvnhox4iFn",
    "outputId": "a9590d1f-fc1e-44a3-be16-52afa4f0acf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manual gradients\n",
    "\n",
    "a = pelu.trainable_variables[0]\n",
    "b = pelu.trainable_variables[1]\n",
    "manual_grads = (1/b)*tf.maximum(0., x) + (tf.exp(tf.minimum(0., x)/b)-1)\n",
    "tf.reduce_all(tf.abs(manual_grads - auto_grads) < 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GT6U91PeobK1"
   },
   "outputs": [],
   "source": [
    "#Same procedure for beta\n",
    "x = tf.cast(tf.linspace(-5, 5, 200), tf.float32)\n",
    "with tf.GradientTape() as t:\n",
    "  t.watch(x)\n",
    "  y = pelu(x)\n",
    "auto_grads_b = t.jacobian(y,pelu.trainable_variables[1])\n",
    "auto_grads_b = tf.reshape(auto_grads_b, [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dIaPMDA--R5I",
    "outputId": "70ead62f-ab6a-4dcb-ab8b-bc2be3fe301e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Manual gradients\n",
    "\n",
    "manual_grads_b = (-a/tf.pow(b, 2))*tf.maximum(0., x) + (-a/tf.pow(b, 2))*tf.minimum(0., x)*(tf.exp(tf.minimum(0., x)/b))\n",
    "                 \n",
    "tf.reduce_all(tf.abs(manual_grads_b - auto_grads_b) < 1e-4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yjnVl6Ysm7F"
   },
   "source": [
    "### Exercise 3: PELU in practice\n",
    "\n",
    "Consider a simple model built with the PELU activation function, as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "R0zDThKw4ViZ"
   },
   "outputs": [],
   "source": [
    "#Importing the dataset using tensorflow datasets\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "#We'll use the fashion-mnist dataset\n",
    "\n",
    "#Loading the dataset\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "#preprocessing the data\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HF5S67DDs7xr",
    "outputId": "6ca85efe-6219-40ad-f3e4-669afa437276"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "pelu_3 (PELU)                (None, 50)                100       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,860\n",
      "Trainable params: 39,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(layers=[\n",
    "      #We added an addition layer to flatten pixels                             \n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(50),\n",
    "      PELU(50),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tXjBu_U8-s6x"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07_lLAAO-v1h",
    "outputId": "049ace43-a9c3-4b00-a514-4139f11c424b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5079 - accuracy: 0.8206\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3813 - accuracy: 0.8625\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3473 - accuracy: 0.8746\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3264 - accuracy: 0.8808\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3123 - accuracy: 0.8854\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2989 - accuracy: 0.8888\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2900 - accuracy: 0.8925\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2795 - accuracy: 0.8964\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2702 - accuracy: 0.9000\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2657 - accuracy: 0.9015\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2587 - accuracy: 0.9026\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2529 - accuracy: 0.9057\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2465 - accuracy: 0.9072\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2415 - accuracy: 0.9094\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2360 - accuracy: 0.9127\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2319 - accuracy: 0.9129\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2282 - accuracy: 0.9144\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2247 - accuracy: 0.9159\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2210 - accuracy: 0.9173\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2163 - accuracy: 0.9189\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2122 - accuracy: 0.9212\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2096 - accuracy: 0.9220\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2042 - accuracy: 0.9231\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2022 - accuracy: 0.9235\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1989 - accuracy: 0.9257\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1971 - accuracy: 0.9251\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9268\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1922 - accuracy: 0.9279\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1877 - accuracy: 0.9289\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1853 - accuracy: 0.9303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc6fa0d6ac8>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We train our model\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_m8N6pwDbD2z",
    "outputId": "cf18ba3d-4bd8-4638-d126-ea63de3185b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3978 - accuracy: 0.8833\n",
      "\n",
      "Test accuracy: 0.8833000063896179\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuioPpa-DO4M",
    "outputId": "03e4afa7-d9b6-44ed-ec70-73c5fdc7cd2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                39250     \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 39,760\n",
      "Trainable params: 39,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#We do the same but this time we use a standard Relu activation function\n",
    "\n",
    "model_relu = tf.keras.Sequential(layers=[\n",
    "      #We added an addition layer to flatten pixels                             \n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(50),\n",
    "      tf.keras.layers.ReLU(50),\n",
    "      tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_relu.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "VNMG5MkfEMR8"
   },
   "outputs": [],
   "source": [
    "model_relu.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QLCpU-5MERmp",
    "outputId": "2ad81eef-cc80-44f9-b0eb-92f141897927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.5296 - accuracy: 0.8161\n",
      "Epoch 2/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.4023 - accuracy: 0.8575\n",
      "Epoch 3/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3599 - accuracy: 0.8713\n",
      "Epoch 4/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3380 - accuracy: 0.8769\n",
      "Epoch 5/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3195 - accuracy: 0.8838\n",
      "Epoch 6/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3074 - accuracy: 0.8869\n",
      "Epoch 7/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2950 - accuracy: 0.8911\n",
      "Epoch 8/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2832 - accuracy: 0.8950\n",
      "Epoch 9/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2766 - accuracy: 0.8975\n",
      "Epoch 10/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2697 - accuracy: 0.8996\n",
      "Epoch 11/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2625 - accuracy: 0.9025\n",
      "Epoch 12/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2566 - accuracy: 0.9060\n",
      "Epoch 13/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2507 - accuracy: 0.9072\n",
      "Epoch 14/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2465 - accuracy: 0.9091\n",
      "Epoch 15/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2429 - accuracy: 0.9093\n",
      "Epoch 16/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2372 - accuracy: 0.9126\n",
      "Epoch 17/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2331 - accuracy: 0.9133\n",
      "Epoch 18/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2275 - accuracy: 0.9151\n",
      "Epoch 19/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2241 - accuracy: 0.9177\n",
      "Epoch 20/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2200 - accuracy: 0.9173\n",
      "Epoch 21/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2175 - accuracy: 0.9195\n",
      "Epoch 22/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2145 - accuracy: 0.9207\n",
      "Epoch 23/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2090 - accuracy: 0.9217\n",
      "Epoch 24/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2049 - accuracy: 0.9236\n",
      "Epoch 25/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2040 - accuracy: 0.9237\n",
      "Epoch 26/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2021 - accuracy: 0.9253\n",
      "Epoch 27/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1988 - accuracy: 0.9255\n",
      "Epoch 28/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1958 - accuracy: 0.9270\n",
      "Epoch 29/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1951 - accuracy: 0.9285\n",
      "Epoch 30/30\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1927 - accuracy: 0.9272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc6f3618f60>"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We train our model\n",
    "\n",
    "model_relu.fit(train_images, train_labels, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8BNh2tyETOa",
    "outputId": "1536fb86-3902-444f-a238-cb5164074427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8793\n",
      "\n",
      "Test accuracy: 0.8792999982833862\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model_relu.evaluate(test_images,  test_labels)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "#We see that the accuracy is slighter less.This result is consistent with the PELU paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvVbeTDwtdbu"
   },
   "source": [
    "**Exercise 3**: load any classification dataset, and train the model above (using either a custom training loop or `model.fit(...)`). Additionally, compare with a standard ReLU activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkb3cj9r7uUH"
   },
   "source": [
    "### Optional: understanding saving/loading of models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEjaJQT06jh9"
   },
   "source": [
    "TensorFlow has several options for saving or loading objects from the disk:\n",
    "\n",
    "1. [Save and load Keras models](https://www.tensorflow.org/guide/keras/save_and_serialize/)\n",
    "\n",
    "In many cases, custom classes require the implementation of a `get_config` / `from_config` functions to define the serialization behaviour.\n",
    "\n",
    "**Exercise 4 (optional)**: implement the `get_config` method and test your implementation as below (taken from the guide on saving and loading models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "voxx7kntvM0W",
    "outputId": "9faeefd7-348b-4c06-91d0-a7f01e0ce89a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: pelu_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('pelu_model')\n",
    "del PELU # This is needed to remove any reference to PELU from memory\n",
    "reloaded_model = tf.keras.models.load_model('pelu_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "838PN8xN0rIW",
    "outputId": "aadaba94-124d-42b3-e26d-163a1d6394d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fc6fa1eda58>\n",
      "Loaded model: <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fc6f234e9e8>\n"
     ]
    }
   ],
   "source": [
    "print(\"Original model:\", model)\n",
    "print(\"Loaded model:\", reloaded_model) # Observe that the object has been dynamically recreated in absence of the configuration options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rl9dZ3HambSz"
   },
   "source": [
    "### References\n",
    "\n",
    "[1] Clevert, D.A., Unterthiner, T. and Hochreiter, S., 2015. [Fast and accurate deep network learning by exponential linear units (ELUs)](https://arxiv.org/abs/1511.07289). arXiv preprint arXiv:1511.07289.\n",
    "\n",
    "[2] Trottier, L., Gigu, P. and Chaib-draa, B., 2017. [Parametric exponential linear unit for deep convolutional neural networks](https://arxiv.org/abs/1605.09332). In 2017 16th IEEE International Conference on Machine Learning and Applications (ICMLA) (pp. 207-214). IEEE."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "wAEgygyPfO7b",
    "Rl9dZ3HambSz"
   ],
   "name": "ScardapaneHw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
